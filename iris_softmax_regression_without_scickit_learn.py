# -*- coding: utf-8 -*-
"""Iris Softmax Regression without scickit learn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CKiZ841qbX7MyTejPeVIwh0niUqUVSgS

# **Rasoul Qashqaei - Iris Softmax Regression without scickit learn**

Import Library
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

"""load the dataset"""

df = load_iris()

"""**Softmax Regression**"""

def softmax(z):
    exp_z = np.exp(z - np.max(z))
    return exp_z / np.sum(exp_z, axis=1, keepdims=True)

"""**One Hot Encoding**"""

def one_hot_encoding(y):
    n_classes = len(np.unique(y))
    one_hot = np.zeros((len(y), n_classes))
    one_hot[np.arange(len(y)), y] = 1
    return one_hot

"""**Reload iris Data**"""

def load_iris_data():
    X = df.data
    y = df.target
    y_one_hot = one_hot_encoding(y)
    return X, y_one_hot

"""**Train**"""

def train_softmax(X, y, learning_rate=0.01, n_epochs=1000):
    # Initialize weights and biases
    n_samples, n_features = X.shape
    _, n_classes = y.shape
    W = np.random.randn(n_features, n_classes)
    b = np.zeros(n_classes)

    # Gradient descent
    for epoch in range(n_epochs):
        # Forward pass
        z = np.dot(X, W) + b
        y_pred = softmax(z)

        # Compute loss and accuracy
        loss = -np.sum(y * np.log(y_pred))
        accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y, axis=1))

        # Backward pass
        dz = y_pred - y
        dW = np.dot(X.T, dz)
        db = np.sum(dz, axis=0)

        # Update weights and biases
        W -= learning_rate * dW
        b -= learning_rate * db

        # Print progress
        if epoch % 100 == 0:
            print(f"Epoch {epoch}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}")

    return W, b

"""**test**"""

def test_softmax(X, y, W, b):
    # Forward pass
    z = np.dot(X, W) + b
    y_pred = softmax(z)

    # Compute accuracy
    accuracy = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y, axis=1))
    print(f"Test Accuracy: {accuracy:.4f}")

"""**Load Data**"""

X, y = load_iris_data()

"""**Split data into train and test sets**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Train softmax regression model**"""

W, b = train_softmax(X_train, y_train)

"""# Test model"""

test_softmax(X_test, y_test, W, b)